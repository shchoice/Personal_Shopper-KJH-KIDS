{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, LSTM, Dense, concatenate, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, ResNet101\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7568185641650677648\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9292602532574618589\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10274517722882710121\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14912199066\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13177395942986013834\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossless_triplet_loss(y_true, y_pred, N=128, beta=128, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    N  --  The number of dimension \n",
    "    beta -- The scaling factor, N is recommended\n",
    "    epsilon -- The Epsilon value to prevent ln(0)\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    anchor = tf.convert_to_tensor(y_pred[:,0:N])\n",
    "    positive = tf.convert_to_tensor(y_pred[:,N:N*2]) \n",
    "    negative = tf.convert_to_tensor(y_pred[:,N*2:N*3])\n",
    "    \n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),1)\n",
    "    \n",
    "    #Non Linear Values  \n",
    "    \n",
    "    # -ln(-x/N+1)\n",
    "    pos_dist = -tf.math.log(-tf.divide((pos_dist),beta)+1+epsilon)\n",
    "    neg_dist = -tf.math.log(-tf.divide((N-neg_dist),beta)+1+epsilon)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = neg_dist + pos_dist\n",
    "    \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_base_network(in_dims, out_dims, activation='sigmoid'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ResNet101(\n",
    "    include_top=False, weights='imagenet', input_shape=in_dims, pooling='avg', classes=1000))\n",
    "\n",
    "    model.add(Dense(1024, activation = 'relu'))\n",
    "    model.add(Dense(out_dims, activation = activation))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_triplet_gen(gen, data_dir, num_classes, batch_size):\n",
    "    \n",
    "    while True:\n",
    "        anchor_label, neg_label = random.sample(range(0, num_classes), 2)\n",
    "        \n",
    "        POS_DIR = os.path.join(data_dir, CLASS_DICT[anchor_label])\n",
    "        NEG_DIR = os.path.join(data_dir, CLASS_DICT[neg_label])\n",
    "        \n",
    "        POS_filecount = len(os.listdir(os.path.join(POS_DIR, POS_DIR.split(os.path.sep)[-1])))    #POS_DIR 파일 개수 (뎁스 2번 들어가야해서 os.path.join~ 해주기)\n",
    "        NEG_filecount = len(os.listdir(os.path.join(NEG_DIR, NEG_DIR.split(os.path.sep)[-1])))   #NEG_DIR 파일 개수\n",
    "        \n",
    "        if  POS_filecount < batch_size or NEG_filecount < batch_size:    #파일 개수가 batch_size 미만이면 처음으로 돌아가서 클래스 다시 선택\n",
    "            continue\n",
    "\n",
    "        anchor_gen = gen.flow_from_directory(POS_DIR, \n",
    "                                             target_size=(224, 224),\n",
    "                                             batch_size=batch_size,\n",
    "                                             color_mode='rgb')\n",
    "\n",
    "        pos_gen = gen.flow_from_directory(POS_DIR,\n",
    "                                          target_size=(224, 224),\n",
    "                                          batch_size=batch_size,\n",
    "                                          color_mode='rgb')\n",
    "\n",
    "        neg_gen = gen.flow_from_directory(NEG_DIR, \n",
    "                                          target_size=(224, 224),\n",
    "                                          batch_size=batch_size,\n",
    "                                          color_mode='rgb')\n",
    "    \n",
    "#         print(\"Anchor: {} , Neg: {}\".format(anchor_label, neg_label))\n",
    "        X1i = anchor_gen.next()\n",
    "        X2i = pos_gen.next()\n",
    "        X3i = neg_gen.next()\n",
    "        \n",
    "        yield [X1i[0], X2i[0], X3i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5621"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../masked_moved2'\n",
    "directory = os.listdir(data_dir)\n",
    "CLASS_DICT = {k:v for k, v in enumerate(directory)}\n",
    "\n",
    "gen = ImageDataGenerator(rescale=1./255)\n",
    "num_classes = len(CLASS_DICT)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dims = (224, 224, 3)    # (28, 28, 1)\n",
    "out_dims = 128\n",
    "\n",
    "# Create the 3 inputs\n",
    "anchor_in = Input(shape=in_dims, name='anchor')\n",
    "pos_in = Input(shape=in_dims, name='positive')\n",
    "neg_in = Input(shape=in_dims, name='negative')\n",
    "\n",
    "# with tf.compat.v1.Session(config=config):\n",
    "    # Share base network with the 3 inputs\n",
    "base_network = res_base_network(in_dims, out_dims)\n",
    "anchor_out = base_network(anchor_in)\n",
    "pos_out = base_network(pos_in)\n",
    "neg_out = base_network(neg_in)\n",
    "    \n",
    "merged_vector = concatenate([anchor_out, pos_out, neg_out], axis=-1)\n",
    "\n",
    "# Define the trainable model\n",
    "model = Model(inputs=[anchor_in, pos_in, neg_in], outputs=merged_vector)\n",
    "\n",
    "for layer in base_network.layers[0].layers[:-21]:\n",
    "    layer.trainable=False\n",
    "\n",
    "for layer in base_network.layers[0].layers[-21:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_network.layers[0].layers[:-21]:\n",
    "    layer.trainable=False\n",
    "\n",
    "for layer in base_network.layers[0].layers[-21:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f878c194ba8>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7f878c194c50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f878c194fd0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f878c0c2978>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f878c0cb438>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7f878c0c2518>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f878c0c2cc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f878c079da0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f878c0799b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f878c021e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f878c02a048>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f878c04ec88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f878c055b38>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f878c072ac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f878c0550f0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f878c072e80>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87747d8d30>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87747dfbe0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87747df198>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87747df4a8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774787dd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774799048>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877478e208>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87747405c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f877474a080>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774740278>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774770668>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8774777128>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774770320>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87747709b0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f877471fa90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774727550>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877471f748>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87746ceb38>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87746d45f8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87746ce7f0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f878c428a58>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f878c428a90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f878c428630>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87746f6c88>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f877467eac8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87746a7dd8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87746ac128>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774655f98>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774655f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f878c428668>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877465c048>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87746f6fd0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774601d68>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f877460bc50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f877460b1d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877460b4e0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87746386d8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87746386a0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774638978>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87745ea8d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87745ea898>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87745eac18>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774599a90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8774599a58>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774599eb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774599e80>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774549fd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774549c88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774551048>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774574dd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87744fecc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87744fe240>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774525ef0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8774530e80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774530080>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774530710>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87744de908>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87744de8d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87744deba8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774490b00>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774490ac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774490f28>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f877443dcc0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f877443dc88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f877443d978>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774476d30>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774476cf8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774425b00>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87744250b8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87743cadd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87743d3cc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87744451d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87743d3240>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f877446bb70>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87743f6ef0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8774381e80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774381080>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774381710>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87743b0908>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87743b08d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87743b0ba8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774360b00>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774360ac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774360f28>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f877430fcc0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f877430fc88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f877430f978>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87743171d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87742bcb70>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87742c8d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87742c8048>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87742eaeb8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87742f4ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87742f40f0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87742a35f8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87742a35c0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87742a3940>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87742a39e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774252b38>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774252b00>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774252f98>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774200d30>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774200cf8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87742009e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774231ef0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8774231eb8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87741ba208>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87741ba278>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87741decc0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87741eaf60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87741ea128>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774199668>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774199630>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87741999b0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774147828>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87741477f0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774147b70>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774147c18>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774175d68>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774175d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774101438>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774122f60>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774122f28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877412d278>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87740d3d30>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87740dfc18>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87740df198>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87740df4a8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774080f60>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f877408a668>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877408a940>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f877403d898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f877403d860>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f877403dbe0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8774068a58>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8774068a20>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8774068e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8774068e48>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748663f98>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748663f60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874866c668>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748613da0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874861bc88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874861b208>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748641eb8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87485c9e48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87485c9048>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87485c96d8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87485fa8d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87485fa898>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87485fab70>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87485a7ac8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87485a7a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87485a7ef0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748557c88>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8748557c50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748557940>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748560198>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748506dd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748510cf8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748510240>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748532e80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874853feb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874853f0b8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87484ee5c0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87484ee588>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87484ee908>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87484ee9b0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874849db00>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874849dac8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874849de48>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874844bcf8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874844bcc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874844b9b0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748478eb8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8748478e80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87484821d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748482240>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874842bc88>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748434f28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87484340f0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87483e4630>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87483e45f8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87483e4978>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87483917f0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87483917b8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748391b38>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748391be0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87483bfd30>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87483bfcf8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87483bf9e8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748370f28>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748370ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748377240>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874831ecf8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8748327be0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748327160>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748327470>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87482ceeb8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87482d6630>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87482d6908>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748286860>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748286828>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748286ba8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87482b3a20>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87482b39e8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87482b3e48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87482b3e10>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748262f60>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748262f28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874826b630>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748212d68>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874821bc50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874821b1d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748241e80>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87481cbe10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87481cb160>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87481cb6a0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87481fa898>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87481fa860>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87481fab38>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87481a7a90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87481a7a58>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87481a7eb8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748158c50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f8748158c18>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748158ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748160780>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748107da0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748112cc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748112208>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748135ef0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748141e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748141080>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f87480ef588>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f87480ef550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f87480ef8d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87480ef978>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874809bac8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874809ba90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874809be10>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874804ccc0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f874804cc88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f874804c978>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f874807de80>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f874807de48>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748004160>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f8748004208>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f8748029c50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f8748033ef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f87480330b8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c7dc5f8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c7dc5c0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c7dc940>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c7887b8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c788780>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c788b00>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c788ba8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c7bbcf8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c7bbcc0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c7bb9b0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c767ef0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c767eb8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c765208>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c715cc0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c718ba8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c718128>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c718438>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c6c4e80>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c6ce5f8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c6ce8d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c67e828>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c67e7f0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c67eb70>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c6ad9e8>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c6ad9b0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c6ade10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c6addd8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c65cf28>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c65cef0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c6665f8>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c609d30>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c615c18>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c615198>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c639e48>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c5c1dd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c5c1128>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c5c1668>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c5f1860>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c5f1828>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c5f1b00>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c5a3a58>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c5a3a20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c5a3e80>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c550c18>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c550be0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c550e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c50ac88>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c50ac50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c52df60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c538048>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c4dbd30>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c4e5c18>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c550f28>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c4e5198>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c4ffd68>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c48ae48>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c494dd8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c494128>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c494668>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c443860>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c443828>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c443b00>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c473a58>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c473a20>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c473e80>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c423c18>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c423be0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c423e80>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c423f28>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c3cfd68>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c3dac88>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c3da1d0>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c37eeb8>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c388e48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f872c388048>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x7f872c3b7550>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7f872c341048>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f872c3b7208>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7f872c3b7898>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_network.layers[0].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traninable layers: 21\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for layer in base_network.layers[0].layers:\n",
    "    if layer.trainable: cnt +=1\n",
    "print('traninable layers: {}'.format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001, clipnorm=3.0),\n",
    "                    loss=lossless_triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101 (Model)            (None, 2048)              42658176  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "=================================================================\n",
      "Total params: 44,887,552\n",
      "Trainable params: 11,160,704\n",
      "Non-trainable params: 33,726,848\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101 (Model)            (None, 2048)              42658176  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "=================================================================\n",
      "Total params: 44,887,552\n",
      "Trainable params: 11,160,704\n",
      "Non-trainable params: 33,726,848\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor (InputLayer)             [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 128)          44887552    anchor[0][0]                     \n",
      "                                                                 positive[0][0]                   \n",
      "                                                                 negative[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 44,887,552\n",
      "Trainable params: 11,160,704\n",
      "Non-trainable params: 33,726,848\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-bdeece7451f3>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps\n",
      "Epoch 1/15\n",
      "1/1 [==============================] - 19s 19s/step - loss: 3.8185\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.6520\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.6241\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.5112\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3992\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3822\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.2924\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.2158\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1488\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.0671\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9850\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9554\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.9518\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.7824\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.8378\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='./trained/unfreeze_test/{epoch:06d}-{loss:.4f}.h5')]\n",
    "\n",
    "# Training the model\n",
    "H = model.fit_generator(input_triplet_gen(gen, data_dir, num_classes, batch_size),\n",
    "              steps_per_epoch = 1, \n",
    "              epochs=5, \n",
    "              callbacks = my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-78a31989cd6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#weights 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_weights_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./trained/resnet101_detectron_unfreeze21/000018-1.2427.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   1221\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_legacy_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     weight_values = preprocess_weights_for_loading(\n\u001b[0;32m--> 689\u001b[0;31m         layer, weight_values, original_keras_version, original_backend)\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m       raise ValueError('Layer #' + str(k) + ' (named \"' + layer.name +\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sequential'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m    294\u001b[0m                      non_trainable_weights[:num_non_trainable_weights]),\n\u001b[1;32m    295\u001b[0m             \u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             original_backend=original_backend)\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mnew_trainable_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_trainable_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnew_non_trainable_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_trainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_time_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sequential'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_nested_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mconvert_nested_model\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m    294\u001b[0m                      non_trainable_weights[:num_non_trainable_weights]),\n\u001b[1;32m    295\u001b[0m             \u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_keras_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             original_backend=original_backend)\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mnew_trainable_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_trainable_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mnew_non_trainable_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_trainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mpreprocess_weights_for_loading\u001b[0;34m(layer, weights, original_keras_version, original_backend)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m       \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ConvLSTM2D'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "#weights 로드\n",
    "model_weights_dir = './trained/resnet101_detectron_unfreeze21/000018-1.2427.h5'\n",
    "model.load_weights(model_weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-f53bece47fea>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 16s 16s/step - loss: 2.7260\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6293\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6185\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.6427\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.4556\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='./trained/py_test/{epoch:06d}-{loss:.4f}.h5')]\n",
    "\n",
    "# Training the model\n",
    "H = model.fit_generator(input_triplet_gen(gen, data_dir, num_classes, batch_size),\n",
    "              steps_per_epoch = 1, \n",
    "              epochs=5, \n",
    "              callbacks = my_callbacks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
