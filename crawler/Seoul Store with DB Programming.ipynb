{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--filepath'], dest='filepath', nargs=None, const=None, default='categorized_tong.json', type=None, choices=None, help='Directory to save item info', metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import argparse\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from builtins import open\n",
    "from time import sleep\n",
    "import cx_Oracle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--isfirst', default=True,\n",
    "                    help=\"Crawling for the first time or not\")\n",
    "parser.add_argument('--num', default=1000,\n",
    "                    help=\"Number of items to fetch per category\")\n",
    "parser.add_argument('--filepath', default='categorized_tong.json',\n",
    "                    help=\"Directory to save item info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: use options instead of chrome_options\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "path='/home/ubuntu/chromedriver'    #크롬드라이버 경로\n",
    "options=webdriver.ChromeOptions()     #크롬드라이버 옵션 추가(안 할 시 에러)\n",
    "options.add_argument('--disable-extensions')\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "driver=webdriver.Chrome(path, chrome_options=options)  #드라이버 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import os\n",
    "from sqlalchemy import types, create_engine\n",
    "\n",
    "os.environ[\"NLS_LANG\"] = \".AL32UTF8\"    \n",
    "    \n",
    "START_VALUE = u\"Unicode \\u3042 3\".encode('utf-8')\n",
    "EVALUE = u\"Unicode \\u3042 6\".encode('utf-8')\n",
    "\n",
    "conn = create_engine(\"oracle+cx_oracle://oddeye:oddeye@15.164.247.135/:1522/MODB\",encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import os\n",
    "# os.putenv('NLS_LANG', 'KOREAN_KOREA.KO16MSWIN949')\n",
    "os.environ[\"NLS_LANG\"] = \".AL32UTF8\"\n",
    " \n",
    "conn = cx_Oracle.connect('oddeye/1234@15.164.247.135:1522/MODB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"insert into test(product_ID, SUPER_CATEGORY, BASE_CATEGORY, SUB_CATEGORY, IMG_URL, PRODUCT_URL) values (:1, :2, :3, :4, :5, :6)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.execute(sql, ('1234', 2, 3, 4, 'bbb', 'bbb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "ORA-01008: not all variables bound",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-55b9f621bd7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1234'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'super_category'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'base_category'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sub_category'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'img_url'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'bbb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_url'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'bbb'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m: ORA-01008: not all variables bound"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "curs.execute(None, {'product_id': '1234', 'super_category' : 2, 'base_category': 3, 'sub_category':4, 'img_url':'bbb', 'product_url':'bbb'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "curs = conn.cursor()\n",
    "curs.execute(\"select * from test1\")\n",
    "for row in curs:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = {\n",
    "    1002: {\"super_category\": 0, \"category\": 0, \"sub_category\": 0, \"name\": \"롱슬리브\"},\n",
    "    1003: {\"super_category\": 0, \"category\": 0, \"sub_category\": 1, \"name\": \"숏슬리브\"},\n",
    "    1004: {\"super_category\": 0, \"category\": 0, \"sub_category\": 2, \"name\": \"슬리브리스\"},\n",
    "    1005: {\"super_category\": 0, \"category\": 0, \"sub_category\": 3, \"name\": \"크롭 탑\"},\n",
    "    1006: {\"super_category\": 0, \"category\": 0, \"sub_category\": 4, \"name\": \"폴로 셔츠\"},\n",
    "    1008: {\"super_category\": 0, \"category\": 1, \"sub_category\": 5, \"name\": \"후디\"},\n",
    "    1010: {\"super_category\": 0, \"category\": 1, \"sub_category\": 6, \"name\": \"스웨트셔츠\"},\n",
    "    1009: {\"super_category\": 0, \"category\": 1, \"sub_category\": 7, \"name\": \"집업후디\"},\n",
    "    1012: {\"super_category\": 0, \"category\": 2, \"sub_category\": 8, \"name\": \"롱 슬리브\"},\n",
    "    1013:{\"super_category\": 0, \"category\": 2, \"sub_category\": 9, \"name\": \"숏 슬리브\"},\n",
    "    1014: {\"super_category\": 0, \"category\": 2, \"sub_category\": 10, \"name\": \"블라우스\"},\n",
    "    1016: {\"super_category\": 0, \"category\": 3, \"sub_category\": 11, \"name\": \"라운드넥\" },\n",
    "    1017: {\"super_category\": 0, \"category\": 3, \"sub_category\": 12, \"name\": \"브이넥\"},\n",
    "    1018: {\"super_category\": 0, \"category\": 3, \"sub_category\": 13, \"name\": \"터틀넥\"},\n",
    "    1019: {\"super_category\": 0, \"category\": 3, \"sub_category\": 14, \"name\": \"베스트\"},\n",
    "    1020: {\"super_category\": 0, \"category\": 3, \"sub_category\": 15, \"name\": \"가디건\"},\n",
    "    \n",
    "    1025: {\"super_category\": 1, \"category\": 4, \"sub_category\": 16, \"name\": \"미니\"},\n",
    "    1026: {\"super_category\": 1, \"category\": 4, \"sub_category\": 17, \"name\": \"미디/롱\"},\n",
    "    1028: {\"super_category\": 1, \"category\": 5, \"sub_category\": 18, \"name\": \"치노\"},\n",
    "    1034: {\"super_category\": 1, \"category\": 5, \"sub_category\": 19, \"name\": \"스웨트팬츠\"},\n",
    "    1031: {\"super_category\": 1, \"category\": 5, \"sub_category\": 20, \"name\": \"스트레이트\"},\n",
    "    1032: {\"super_category\": 1, \"category\": 5, \"sub_category\": 21, \"name\": \"와이드\"},\n",
    "    1030: {\"super_category\": 1, \"category\": 5, \"sub_category\": 22, \"name\": \"스키니\"},\n",
    "    1033: {\"super_category\": 1, \"category\": 5, \"sub_category\": 23, \"name\": \"부츠컷\"},\n",
    "    1029: {\"super_category\": 1, \"category\": 5, \"sub_category\": 24, \"name\": \"쇼츠\"},\n",
    "    1035: {\"super_category\": 1, \"category\": 5, \"sub_category\": 25, \"name\": \"레깅스\"},\n",
    "    1040: {\"super_category\": 1, \"category\": 6, \"sub_category\": 26, \"name\": \"스트레이트\"},\n",
    "    1041: {\"super_category\": 1, \"category\": 6, \"sub_category\": 27, \"name\": \"와이드\"},\n",
    "    1039: {\"super_category\": 1, \"category\": 6, \"sub_category\": 28, \"name\": \"스키니\"},\n",
    "    1042: {\"super_category\": 1, \"category\": 6, \"sub_category\": 29, \"name\": \"부츠컷\"},\n",
    "    1043: {\"super_category\": 1, \"category\": 6, \"sub_category\": 30, \"name\": \"크롭\"},\n",
    "    1038: {\"super_category\": 1, \"category\": 6, \"sub_category\": 31, \"name\": \"스커트\"},\n",
    "    1037: {\"super_category\": 1, \"category\": 6, \"sub_category\": 32, \"name\": \"쇼츠\"},\n",
    "    \n",
    "    1022: {\"super_category\": 2, \"category\": 7, \"sub_category\": 33, \"name\": \"미니\"},\n",
    "    1023: {\"super_category\": 2, \"category\": 7, \"sub_category\": 34, \"name\": \"미디/맥시\"},\n",
    "    1273: {\"super_category\": 2, \"category\": 7, \"sub_category\": 35, \"name\": \"드레스\"},\n",
    "    1045: {\"super_category\": 2, \"category\": 8, \"sub_category\": 36, \"name\": \"올인원\"},\n",
    "    1046: {\"super_category\": 2, \"category\": 8, \"sub_category\": 37, \"name\": \"점프수트\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products1(category_dict, num, filepath):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - category_dict: dict. 카테고리 고유번호: 카테고리 정보 키밸류 페어를 원소로 함\n",
    "    - num: int. url당 크롤링할 아이템 수\n",
    "    - filepath: str. 크롤링 결과를 저장할 json 파일 경로\n",
    "    \n",
    "    Return:\n",
    "    - 없음\n",
    "    \"\"\"\n",
    "    product_set = set()   #중복 크롤링 거르기 위한 셋. product_url을 원소로 함\n",
    "\n",
    "    wait_time = 300\n",
    "    browser = webdriver.Chrome('chromedriver')   #크롬 브라우저 실행\n",
    "    wait = WebDriverWait(browser, wait_time)\n",
    "    \n",
    "    for cat in category_dict:\n",
    "        url = 'https://www.seoulstore.com/categories/{}/regDatetime/desc'.format(str(cat))\n",
    "        browser.get(url)\n",
    "        body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "        count = 0    #더 이상 로드되는 데이터가 없을 시 크롤링 종료하기 위해 필요한 count임\n",
    "        prev_posts_count = 0\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'products_container')))  #페이지 로딩 기다림\n",
    "        time.sleep(2)\n",
    "        ele_posts = browser.find_element_by_class_name('products_container').find_elements_by_class_name('image_container')\n",
    "            \n",
    "        ##########추가한 부분###########\n",
    "        while len(ele_posts) < num:\n",
    "            body.send_keys(Keys.PAGE_DOWN)\n",
    "            ele_posts = browser.find_element_by_class_name('products_container').find_elements_by_class_name('image_container')\n",
    "\n",
    "            cur_posts_count = len(ele_posts)\n",
    "            if prev_posts_count == cur_posts_count:\n",
    "                count += 1\n",
    "            else: count = 0\n",
    "            if count > 50:\n",
    "                    break\n",
    "\n",
    "            prev_posts_count = cur_posts_count\n",
    "        ##########추가한 부분 끝##########\n",
    "       \n",
    "        cat_post_count = 0   #카테고리별 크롤링된 아이템 수 세기\n",
    "        for ele in ele_posts:\n",
    "            product_url= ele.find_element_by_tag_name('a').get_attribute('href')\n",
    "            key = product_url.split('/')[-2]\n",
    "            if key not in product_set:\n",
    "                try:\n",
    "                    dict_post = { \"product_url\": product_url }\n",
    "                    dict_post['key'] = key\n",
    "                    wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'ImageLoader.ratio_1_1.loaded')))\n",
    "                    ele_img = ele.find_element_by_class_name('ImageLoader.ratio_1_1.loaded')\n",
    "                    dict_post[\"img_url\"] = ele_img.get_attribute(\"src\")\n",
    "                    dict_post[\"sub_category\"] = category_dict[cat][\"sub_category\"]\n",
    "                    dict_post[\"category\"] = category_dict[cat][\"category\"]\n",
    "                    dict_post[\"super_category\"] = category_dict[cat][\"super_category\"]\n",
    "                    product_set.add(key)\n",
    "                    \n",
    "                    if isfirst == True: pass\n",
    "                    else:    #첫번째 크롤링 아닐 경우 저장 경로 바꿈\n",
    "                        now = time.localtime()\n",
    "                        filepath_temp = '_'.join(os.path.splitext(filepath)[0].split('_')[:-2])\n",
    "                        filepath = filepath_temp +'_'+time.strftime('%y%m%d_%I%M%S', now) + os.path.splitext(filepath)[1]\n",
    "                    \n",
    "                    out = json.dumps(dict_post, ensure_ascii=False)    #json 형식으로 정보 변환\n",
    "                    out += ', '    #아이템 정보 분류하기 위해 끝에 쉼표 추가\n",
    "                    \n",
    "                    sql = \"insert into test(product_ID, SUPER_CATEGORY, BASE_CATEGORY, SUB_CATEGORY, IMG_URL, PRODUCT_URL) values (:1, :2, :3, :4, :5, :6)\"\n",
    "                    a = dict_post[\"img_url\"]\n",
    "                    \n",
    "                    with open(filepath, \"a\", encoding=\"utf-8\") as f:\n",
    "                        f.write(out)\n",
    "                    cat_post_count +=1\n",
    "                \n",
    "                except: continue\n",
    "        print(\"saved {} items from {} section{}\".format(cat_post_count, category_dict[cat]['name'], isntfirst_txt))\n",
    "   \n",
    "    #[]로 감싸주기\n",
    "    with open(filepath, encoding=\"utf-8\") as f:\n",
    "        file = f.read()\n",
    "\n",
    "    removed_comma = file[:-1]\n",
    "    bracketed = '[' + removed_comma + ']'\n",
    "\n",
    "    with open(filepath, 'w', encoding = 'utf-8') as f:\n",
    "        f.write(bracketed)\n",
    "        \n",
    "    print('Finished crawling. Saved as {}'.format(filepath))\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products2(category_dict, filepath):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    - category_dict: dict. 카테고리 고유번호: 카테고리 정보 키밸류 페어를 원소로 함\n",
    "    - filepath: str. 기존 크롤링 결과가 저장된 json 파일 경로\n",
    "    \n",
    "    Return:\n",
    "    - 없음\n",
    "    \"\"\"\n",
    "    with open(filepath) as data_file:    # 기존 파일 읽어오기\n",
    "        existing = json.load(data_file)\n",
    "    \n",
    "    product_set = set([e['key'] for e in existing])   #중복 크롤링 거르기 위한 셋. product_url을 원소로 함\n",
    "    \n",
    "    #새로 저장할 경로\n",
    "    now = time.localtime()\n",
    "    filepath_temp = '_'.join(os.path.splitext(filepath)[0].split('_')[:-2])\n",
    "    new_filepath = filepath_temp +'_'+time.strftime('%y%m%d_%I%M%S', now) + os.path.splitext(filepath)[1]\n",
    "\n",
    "    wait_time = 300\n",
    "    browser = webdriver.Chrome('chromedriver')   #크롬 브라우저 실행\n",
    "    wait = WebDriverWait(browser, wait_time)\n",
    "    \n",
    "    print(time.strftime('start at %Y-%m-%d %I:%M:%S %p', time.localtime()))    \n",
    "    for cat in category_dict:\n",
    "        url = 'https://www.seoulstore.com/categories/{}/regDatetime/desc'.format(str(cat))\n",
    "        browser.get(url)\n",
    "        body = browser.find_element_by_tag_name('body')\n",
    "        \n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'products_container')))  #페이지 로딩 기다림\n",
    "        body.send_keys(Keys.PAGE_DOWN)  #초기 로딩 안 될 때 있어서 한 번 스크롤\n",
    "        time.sleep(2)\n",
    "        ele_posts = browser.find_element_by_class_name('products_container').find_elements_by_class_name('image_container')\n",
    "        product_url_temp_first = ele_posts[0].find_element_by_tag_name('a').get_attribute('href')\n",
    "        if product_url_temp_first in product_set: print('{} is up to date'.format(category_dict[cat]['name']))\n",
    "            \n",
    "        while True:  # 여기서 num은 사용 안 함, 기존 상품이 이미 저장되어 있다는 전제 하에 기존 상품이 보일 때까지 무한\n",
    "            ele_posts = browser.find_element_by_class_name('products_container').find_elements_by_class_name('image_container')\n",
    "            product_url_temp_last = ele_posts[-1].find_element_by_tag_name('a').get_attribute('href')\n",
    "                \n",
    "            # 기존 상품이 보일 시\n",
    "            if product_url_temp_last in product_set: break\n",
    "                \n",
    "            #기존 상품이 안 보일 시 더 스크롤\n",
    "            else: _=[body.send_keys(Keys.PAGE_DOWN) for _ in range(5)]\n",
    "            \n",
    "        \n",
    "    cat_post_count = 0   #카테고리별 크롤링된 아이템 수 세기\n",
    "    for ele in ele_posts:\n",
    "        product_url= ele.find_element_by_tag_name('a').get_attribute('href')\n",
    "        key = product_url.split('/')[-2]\n",
    "        if key not in product_set:\n",
    "            try:\n",
    "                dict_post = { \"product_url\": product_url }\n",
    "                dict_post['key'] = key\n",
    "                wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'ImageLoader.ratio_1_1.loaded')))\n",
    "                ele_img = ele.find_element_by_class_name('ImageLoader.ratio_1_1.loaded')\n",
    "                dict_post[\"img_url\"] = ele_img.get_attribute(\"src\")\n",
    "                dict_post[\"sub_category\"] = category_dict[cat][\"sub_category\"]\n",
    "                dict_post[\"category\"] = category_dict[cat][\"category\"]\n",
    "                dict_post[\"super_category\"] = category_dict[cat][\"super_category\"]\n",
    "                product_set.add(key)\n",
    "                    \n",
    "                out = json.dumps(dict_post, ensure_ascii=False)    #json 형식으로 정보 변환\n",
    "                out += ', '    #아이템 정보 분류하기 위해 끝에 쉼표 추가\n",
    "                with open(new_filepath, \"a\", encoding=\"utf-8\") as f:\n",
    "                    f.write(out)\n",
    "                cat_post_count +=1\n",
    "                \n",
    "            except: continue\n",
    "        \n",
    "    print(\"saved {} new items from {} section{}\".format(cat_post_count, category_dict[cat]['name']))\n",
    "    \n",
    "    #[]로 감싸주기\n",
    "    with open(new_filepath, encoding=\"utf-8\") as f:\n",
    "        file = f.read()\n",
    "\n",
    "    removed_comma = file[:-1]\n",
    "    bracketed = '[' + removed_comma + ']'\n",
    "\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:       #기존 파일에 새로 크롤링한 내용 덧붙이기\n",
    "        total_file = existing.extend(bracketed)\n",
    "        f.write(total_file)\n",
    "\n",
    "    with open(new_filepath, 'w', encoding = 'utf-8') as f:    #새로 크롤링한 내용만 담긴 파일 생성\n",
    "        f.write(bracketed)\n",
    "\n",
    "    print('Finished updating. Saved as {}'.format(new_filepath))\n",
    "    browser.close()\n",
    "    return new_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--isfirst ISFIRST] [--num NUM]\n",
      "                             [--filepath FILEPATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/0/jupyter/kernel-0ef4379d-7021-45de-98fd-d7e933a95956.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def DownloadSingleFile(fileURL, key):\n",
    "    print('Downloading image...')\n",
    "    DIR = f'./seoulstore_ALL'\n",
    "    if not os.path.exists(DIR):\n",
    "        os.mkdir(DIR)\n",
    "    fileName = DIR + '/' + str(key) + '.jpg'\n",
    "    urllib.request.urlretrieve(fileURL, fileName)\n",
    "    print('Done. ' + fileName)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    args = parser.parse_args()\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Starting PROCESS 1: Fetching item info')\n",
    "    print('-------------------------------------------------------')\n",
    "    if args.isfirst == True:\n",
    "        get_products1(category_dict, args.num, args.filepath)\n",
    "        filepath = args.filepath\n",
    "\n",
    "    else:\n",
    "        new_filepath = get_products2(category_dict, args.filepath)\n",
    "        filepath = new_filepath\n",
    "    print('-------------------------------------------------------')\n",
    "    print('Starting PROCESS 2: Image Download')\n",
    "    print('-------------------------------------------------------')\n",
    "\n",
    "\n",
    "    with open(filepath) as data_file:\n",
    "        data = json.load(data_file)\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "        imgURL = data[i]['img_url']\n",
    "        key = data[i]['key']\n",
    "        DownloadSingleFile(imgURL, key)\n",
    "        count += 1\n",
    "    print(\"Successfully downloaded {} images\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36]",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
